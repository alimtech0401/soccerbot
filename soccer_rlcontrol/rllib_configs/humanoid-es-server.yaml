humanoid-es:
    env: gym_soccerbot:walk-forward-norm-v1
    run: ES
    checkpoint_freq: 20
    max_failures: 10
    checkpoint_at_end: true
    local_dir: ./results/
    stop:
        timesteps_total: 1000000000
    config:
        # Works for both torch and tf.
        framework: tf
        env_config:
            env_name: gym_soccerbot:walk-omni-v0
            goal:
                    - 2
                    - 0
            start_ang: !!float 15.
        extra_python_environs_for_driver:
            OMP_NUM_THREADS: 32
        num_workers: 31
        # num_cpus_per_worker: 0.001
        num_envs_per_worker: 32
        remote_worker_envs: true
        horizon: 1024
        num_gpus: 1
        model:
            fcnet_hiddens: [128, 128]
            fcnet_activation: tanh

        action_noise_std: 0.01
        l2_coeff: 0.005
        noise_stdev: 0.02
        episodes_per_batch: 1000
        train_batch_size: 10000
        eval_prob: 0.003
        return_proc_mode: centered_rank
        # num_workers: 10
        stepsize: 0.01
        observation_filter: MeanStdFilter
        noise_size: 250000000
        report_length: 10
        # ARS will use Trainer's evaluation WorkerSet (if evaluation_interval > 0).
        # Therefore, we must be careful not to use more than 1 env per eval worker
        # (would break ESPolicy's compute_action method) and to not do obs-
        # filtering.
        evaluation_config:
            num_envs_per_worker: 1
            observation_filter: NoFilter
